________________________________________
üìÑ Report
OCR ‚Üí LLM Pipeline for Math-Heavy CET PDFs (Feasibility & Design)
________________________________________
1. Problem Statement
The goal is to extract, clean, and structure text from scanned CET preparation PDFs that:
‚Ä¢	Are image-based (scanned pages)
‚Ä¢	Contain dense mathematical and physics notation
‚Ä¢	Include MCQs, equations, symbols, subscripts, superscripts, and diagrams
‚Ä¢	Need to be converted into machine-usable LaTeX for storage in a database (question banks, search, analytics)
Traditional PDF-to-text tools fail due to:
‚Ä¢	No embedded text
‚Ä¢	OCR inaccuracies on math-heavy content
‚Ä¢	Loss of structure and formatting
________________________________________
2. Nature of the Input PDFs (Observed)
From the provided example (MHT-CET Physics PDF):
‚Ä¢	Entire document is scanned
‚Ä¢	Contains:
o	Physics formulas (‚àö, Œ£, vectors, Œ∏, Œº, subscripts)
o	MCQs with options A‚ÄìD
o	Step-by-step solutions
o	Diagrams and force/vector sketches
‚Ä¢	Has noise:
o	Watermarks
o	Scan skew
o	Variable font sizes
This places the problem in the category of hard OCR + math normalization, not simple text extraction.
________________________________________
3. Proposed High-Level Pipeline (Validated)
Scanned PDF
 ‚Üí OCRmyPDF + Tesseract
 ‚Üí Raw OCR Text (imperfect)
 ‚Üí Math-aware LLM
 ‚Üí Cleaned & normalized LaTeX
 ‚Üí Structured database storage
This is a modern and realistic document-AI approach, used in ed-tech and research systems.
________________________________________
4. OCR Layer Analysis
4.1 OCRmyPDF + Tesseract (Chosen Solution)
Why this combination works best (free & open source):
‚Ä¢	Designed specifically for scanned PDFs
‚Ä¢	Preserves page layout and reading order
‚Ä¢	Adds a searchable text layer instead of flattening content
‚Ä¢	Allows bulk processing
‚Ä¢	Tunable for DPI, deskewing, noise removal
Expected OCR quality:
‚Ä¢	Plain text: ~90%
‚Ä¢	Math symbols: ~60‚Äì70%
‚Ä¢	Superscripts/subscripts: inconsistent
‚Ä¢	Diagrams: not interpretable
This output is sufficient for downstream LLM repair, but not for direct database usage.
________________________________________
5. Role of the LLM (Critical Clarification)
The LLM is NOT replacing OCR.
It acts as a post-processing and normalization layer, responsible for:
‚Ä¢	Repairing OCR math errors
‚Ä¢	Converting informal math text into valid LaTeX
‚Ä¢	Normalizing notation across questions
‚Ä¢	Preserving MCQ structure
What LLMs are good at
‚Ä¢	Inferring missing math symbols using context
‚Ä¢	Reconstructing standard physics equations
‚Ä¢	Formatting consistent LaTeX
‚Ä¢	Handling CET/JEE-level physics reliably
What LLMs must NOT do
‚Ä¢	Invent missing equations
‚Ä¢	‚ÄúComplete‚Äù partial statements
‚Ä¢	Interpret diagrams
‚Ä¢	Improve or rewrite question wording
________________________________________
6. What Can Go Wrong (Risks & Mitigation)
6.1 Garbage-In ‚Üí Confident Garbage-Out
OCR errors may cause LLMs to confidently produce incorrect equations.
Mitigation:
‚Ä¢	Always store raw OCR alongside cleaned LaTeX
‚Ä¢	Force LLM to mark uncertainty (??)
‚Ä¢	Never discard original OCR text
________________________________________
6.2 Diagram Interpretation
LLMs cannot reliably reconstruct vector or force diagrams.
Mitigation:
‚Ä¢	Treat diagrams as image assets
‚Ä¢	Store references instead of attempting LaTeX reconstruction
________________________________________
6.3 Superscripts & Subscripts
This is the most fragile area (e.g., v2 vs v^2).
Mitigation:
‚Ä¢	Let LLM attempt repair
‚Ä¢	Flag ambiguous cases for review
‚Ä¢	Accept that ~15‚Äì20% may need manual correction
________________________________________
6.4 Hallucination Risk
LLMs may insert standard formulas not present in OCR.
Mitigation (VERY IMPORTANT):
‚Ä¢	Strict prompting: ‚ÄúDo not add content‚Äù
‚Ä¢	One-question-at-a-time processing
‚Ä¢	Structured JSON outputs
‚Ä¢	Temperature = 0
________________________________________
7. Correct Prompting & Architecture (Key Design Choice)
Wrong approach ‚ùå
‚ÄúClean this OCR text and give me LaTeX.‚Äù
Correct approach ‚úÖ
‚Ä¢	Chunk by individual question
‚Ä¢	Provide explicit transformation-only rules
‚Ä¢	Ask for structured output
Example output schema:
{
  "question_latex": "...",
  "options_latex": {
    "A": "...",
    "B": "...",
    "C": "...",
    "D": "..."
  },
  "uncertain_tokens": ["theta vs 0"]
}
Both raw OCR and LLM-cleaned LaTeX must be stored.
________________________________________
8. LLM Selection (Open Source & Local)
8.1 Best Open-Source Models (Hugging Face)
ü•á DeepSeek-Math (7B)
‚Ä¢	Strongest math + physics intuition
‚Ä¢	Excellent LaTeX generation
‚Ä¢	Closest open-source equivalent to GPT-4-level math repair
Risk: Overconfidence ‚Üí must constrain prompts tightly
________________________________________
ü•à Qwen2.5-Math (7B)
‚Ä¢	Excellent instruction-following
‚Ä¢	Cleaner structured outputs (JSON)
‚Ä¢	Slightly weaker physics intuition than DeepSeek
________________________________________
ü•â LLaMA-based Math Models
‚Ä¢	Acceptable but inferior
‚Ä¢	Higher hallucination risk
________________________________________
8.2 Models to Avoid
‚Ä¢	Small general chat models
‚Ä¢	Non-math-tuned LLMs
‚Ä¢	Vision-only OCR models
‚Ä¢	Creative writing‚Äìoptimized models
________________________________________
9. Running Models Locally (Feasibility)
Yes, local execution is feasible.
Typical PC setup:
‚Ä¢	16 GB RAM
‚Ä¢	CPU or modest GPU
‚Ä¢	7B models using 4-bit quantization
Recommended runtimes:
‚Ä¢	Ollama (simplest, CLI-based)
‚Ä¢	LM Studio (GUI, great for testing)
‚Ä¢	Text Generation WebUI (advanced control)
This allows offline, batch processing of large datasets.
________________________________________
10. Expected Accuracy (Realistic Numbers)
Stage	Approx. Accuracy
OCR text	          ~90%
OCR math	          ~60‚Äì70%
LLM math repair	    +15‚Äì25%
Final usable LaTeX	~80‚Äì85%
This is excellent for exam-prep databases and search systems.
________________________________________
11. Recommended Industry-Style Strategy
1.	OCR all PDFs (OCRmyPDF)
2.	Extract text page-wise
3.	Chunk by question
4.	Normalize via math-aware LLM
5.	Auto-accept high-confidence outputs
6.	Flag 15‚Äì20% for manual review
7.	Store both raw and cleaned versions
This balances automation, correctness, and scalability.
________________________________________
12. Final Conclusion
‚Ä¢	The proposed OCR + LLM pipeline is technically sound
‚Ä¢	Fully achievable using free and open-source tools
‚Ä¢	Matches real-world ed-tech document AI practices
‚Ä¢	Requires strict LLM constraints, not blind trust
‚Ä¢	Local execution is practical and scalable
This approach is well-suited for CET / SmartScore-style question banks, analytics, and structured learning systems.________________________________________
